{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo Genético para treinamento da RNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importe os pacotes necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from numpy import array, dtype\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import livelossplot\n",
    "import collections\n",
    "import asyncio\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estrutura do Algoritmo Genético"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações para definir os pesos da RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inserePesosConv2d(lista, j, k, h):\n",
    "\tqtdPesos = 32\n",
    "\tg = 0\n",
    "\twhile(g < qtdPesos):\n",
    "\t\tpeso = random.uniform(-1.0, 1.0)\n",
    "\t\tlista[j][k][h].append(peso)\n",
    "\t\tg += 1\n",
    "\treturn lista\n",
    "\n",
    "def montaConv2d_1():\n",
    "\tcamada = list()\n",
    "\tlista = list() ## no primeiro caso deve ter 3 posições, no segundo caso deve ter 32 posições\n",
    "\n",
    "\tdescendente = 2 ## quantidade de elementos na camada\n",
    "\n",
    "\ti = 0\n",
    "\twhile(i < descendente):\n",
    "\t\tlista = []\n",
    "\t\tif( i == 0):\n",
    "\t\t\ttamanhoSubCamada = 3\n",
    "\t\t\tj = 0\n",
    "\t\t\twhile(j < tamanhoSubCamada):\n",
    "\t\t\t\tsubLista = list()\n",
    "\t\t\t\tlista.append(subLista)\n",
    "\n",
    "\t\t\t\ttamanhoSubSubCamada = 3\n",
    "\t\t\t\tk = 0\n",
    "\t\t\t\twhile(k < tamanhoSubSubCamada):\n",
    "\t\t\t\t\tsubsubLista = list()\n",
    "\t\t\t\t\tlista[j].append(subsubLista)\n",
    "\n",
    "\t\t\t\t\ttamanhoSubSubSubcamada = 3\n",
    "\t\t\t\t\th = 0\n",
    "\t\t\t\t\twhile(h < tamanhoSubSubSubcamada):\n",
    "\t\t\t\t\t\tsubsubsubLista = list()\n",
    "\t\t\t\t\t\tlista[j][k].append(subsubsubLista)\n",
    "\n",
    "\t\t\t\t\t\tlista = inserePesosConv2d(lista, j, k, h)\n",
    "\n",
    "\t\t\t\t\t\th += 1\n",
    "\t\t\t\t\tk += 1\n",
    "\t\t\t\tj += 1\n",
    "\t\t\t\t\t\t\n",
    "\t\telif(i == 1):\n",
    "\t\t\tqtdPesos = 32\n",
    "\t\t\tj = 0\n",
    "\t\t\twhile(j < qtdPesos):\n",
    "\t\t\t\tlista.append(0.0)\n",
    "\t\t\t\tj += 1\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Não pode ter mais que duas posições\")\n",
    "\t\t\n",
    "\t\tcamada.append(np.array(lista, dtype='float32'))\n",
    "\t\ti += 1\n",
    "\treturn camada\n",
    "\n",
    "\n",
    "\n",
    "def montaCamada(arraysNaCamada, qtdPorArray):\n",
    "\tcamada = list()\n",
    "\treturn camada \n",
    "\n",
    "def montaBatch_normalization(arraysNaCamada, qtdPorArray):\n",
    "\tcamada = list()\n",
    "\tif(not arraysNaCamada == 0):\n",
    "\t\ti = 0\n",
    "\t\tlista = None\n",
    "\t\t\n",
    "\t\twhile(i < arraysNaCamada):\n",
    "\t\t\tlista = list()\n",
    "\t\t\t\n",
    "\t\t\tpesoAtual = 0\n",
    "\t\t\twhile(pesoAtual < qtdPorArray[i]):\n",
    "\t\t\t\tif(i == 0 or i == 3):\n",
    "\t\t\t\t\tnumero = 1.0\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tnumero = 0.0\n",
    "\n",
    "\t\t\t\tlista.append(numero)\n",
    "\t\t\t\tpesoAtual += 1\n",
    "\n",
    "\t\t\tcamada.append(np.array(lista, dtype='float32'))\n",
    "\t\t\ti = i + 1\n",
    "\n",
    "\treturn camada \n",
    "\n",
    "def montaPesoNaDensa(lista):\n",
    "\tqtdPesos = 32768\n",
    "\tg = 0\n",
    "\twhile(g < qtdPesos):\n",
    "\t\tsub = []\n",
    "\t\tpeso = random.uniform(-1.0, 1.0)\n",
    "\t\tsub.append(peso)\n",
    "\t\tlista.append(sub)\n",
    "\t\tg += 1\n",
    "\treturn lista\n",
    "\n",
    "def montaDensa(arraysNaCamada, qtdPorArray):\n",
    "\tcamada = list()\n",
    "\tif(not arraysNaCamada == 0):\n",
    "\t\ti = 0\n",
    "\t\tlista = None\n",
    "\t\t\n",
    "\t\twhile(i < arraysNaCamada):\n",
    "\t\t\tlista = []\t\n",
    "\t\t\tDEFAULT = 0.0\n",
    "\t\t\tif(i == 0):\n",
    "\t\t\t\tresult = montaPesoNaDensa(lista)\n",
    "\t\t\telif(i == 1):\n",
    "\t\t\t\tpeso = DEFAULT\n",
    "\t\t\t\tlista.append(peso)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"Nao era pra cair aqui\")\n",
    "\n",
    "\t\t\ti = i + 1\n",
    "\t\t\tcamada.append(np.array(lista, dtype='float32'))\n",
    "\t\n",
    "\treturn camada \n",
    "\n",
    "arraysNaCamada = None\n",
    "qtdPorArray = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicia um Indivíduo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_individual():\n",
    "    individual = []\n",
    "    array0 = np.array([],dtype='float32')\n",
    "    array1 = montaConv2d_1() \n",
    "    array2 = montaCamada(0, []) # é vazio\n",
    "    array3 = montaBatch_normalization(4, [32,32,32,32])\n",
    "    array4 = montaCamada(0, []) # é vazio\n",
    "    array5 = montaCamada(0, []) # é vazio\n",
    "    array6 = montaDensa(2, [32768, 1])\n",
    "    array7 = montaBatch_normalization(4, [1,1,1,1])\n",
    "    individual.append(array0)\n",
    "    individual.append(array1)\n",
    "    individual.append(array2)\n",
    "    individual.append(array3)\n",
    "    individual.append(array4)\n",
    "    individual.append(array5)\n",
    "    individual.append(array6)\n",
    "    individual.append(array7)\n",
    "    \n",
    "    return individual\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicia uma nova População"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def init_new_population(population_size):\n",
    "    \n",
    "    new_population = []\n",
    "    \n",
    "    iterator = 0\n",
    "    while (iterator < population_size):\n",
    "        individual = init_individual()\n",
    "        new_population.append(individual)\n",
    "        iterator = iterator + 1\n",
    "    \n",
    "    return(new_population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execução da RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def execute_rna(list0, list1, list2, list3, list4, list5, list6, list7):\n",
    "\n",
    "    dataset = 'dataset'\n",
    "\n",
    "    EPOCHS = 3\n",
    "    INIT_LR = 1e-3\n",
    "    MOMENTUM = 0.8\n",
    "    BS = 5\n",
    "    IMAGE_DIMS = (96, 96, 3)\n",
    "    modelname = 'blood.model'\n",
    "    label = 'lb.pickle'\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    imagePaths = list(paths.list_images(dataset))\n",
    "\n",
    "    for imagePath in imagePaths:\n",
    "        # carrega a imagem, pré-processa e armazena na lista de dados\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "        image = img_to_array(image)\n",
    "        data.append(image)\n",
    "\n",
    "        # extrai o rótulo da classe do caminho da imagem e atualiza a lista de rótulos\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "        labels.append(label)\n",
    "\n",
    "    data = np.array(data, dtype=\"float\") / 255.0\n",
    "    labels = np.array(labels)\n",
    "    print(\"[INFO] data matrix: {:.2f}MB\".format(\n",
    "        data.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    labels = lb.fit_transform(labels)\n",
    "\n",
    "    (trainX, testX, trainY, testY) = train_test_split(data,\n",
    "        labels, test_size=0.2, shuffle=False )\n",
    "\n",
    "    aug = ImageDataGenerator()\n",
    "    width=IMAGE_DIMS[1]\n",
    "    height=IMAGE_DIMS[0]\n",
    "    depth=IMAGE_DIMS[2]\n",
    "    classes=len(lb.classes_)\n",
    "\n",
    "    model = Sequential()\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    if K.image_data_format() == \"channels_first\":\n",
    "        inputShape = (depth, height, width)\n",
    "        chanDim = 1\n",
    "\n",
    "    # CONV => RELU => POOL\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "        input_shape=inputShape, use_bias=True))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(axis=chanDim))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    #set of FC => RELU layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "#     print('original')\n",
    "#     print('#########################################################')\n",
    "#     for layer in model.layers:\n",
    "#         weights = layer.get_weights()\n",
    "#     #     print(weights)\n",
    "\n",
    "    # layer0 = layer[0].get_weights()\n",
    "    #print(model.layers)\n",
    "#     print(model.get_layer(Conv2D,0).get_weights())\n",
    "#     print(model.get_layer(Conv2D,1).get_weights())\n",
    "#     print(model.get_layer(Conv2D,2).get_weights())\n",
    "#     print(model.get_layer(Conv2D,3).get_weights())\n",
    "#     print(model.get_layer(Conv2D,4).get_weights())\n",
    "#     print(model.get_layer(Conv2D,5).get_weights())\n",
    "#     print(model.get_layer(Conv2D,6).get_weights())\n",
    "#     print(model.get_layer(Conv2D,7).get_weights())\n",
    "\n",
    "    #model.summary()    \n",
    "\n",
    "    # Classificador\n",
    "    model.add(Dense(classes))\n",
    "    model.add(Activation(\"tanh\")) #tanh <- Tangente hiperbólica\n",
    "    opt = optimizers.SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS, momentum=MOMENTUM, nesterov=True)\n",
    "    \n",
    "    model.get_layer(Conv2D,0).set_weights(list0)\n",
    "    model.get_layer(Conv2D,1).set_weights(list1)\n",
    "    model.get_layer(Conv2D,2).set_weights(list2)\n",
    "    model.get_layer(Conv2D,3).set_weights(list3)\n",
    "    model.get_layer(Conv2D,4).set_weights(list4)\n",
    "    model.get_layer(Conv2D,5).set_weights(list5)\n",
    "    model.get_layer(Conv2D,6).set_weights(list6)\n",
    "    model.get_layer(Conv2D,7).set_weights(list7)\n",
    "    \n",
    "#     print(model.get_layer(Conv2D,1).get_weights()) \n",
    "#     print(model.get_layer(Conv2D,1).get_weights())\n",
    "#     print(model.get_layer(Conv2D,2).get_weights())\n",
    "#     print(model.get_layer(Conv2D,3).get_weights())\n",
    "#     print(model.get_layer(Conv2D,4).get_weights())\n",
    "#     print(model.get_layer(Conv2D,5).get_weights())\n",
    "#     print(model.get_layer(Conv2D,6).get_weights())\n",
    "#     print(model.get_layer(Conv2D,7).get_weights())\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "        metrics=[\"accuracy\"])\n",
    "    plot_losses = livelossplot.PlotLossesKeras()\n",
    "    H = model.fit_generator(\n",
    "        aug.flow(trainX, trainY, batch_size=BS),\n",
    "        validation_data=(testX, testY),\n",
    "        steps_per_epoch=len(trainX) // BS,\n",
    "        epochs=EPOCHS,\n",
    "        #callbacks=[plot_losses],\n",
    "        verbose=1\n",
    "    )\n",
    "    train_loss = H.history[\"loss\"]\n",
    "    val_loss = H.history[\"val_loss\"]\n",
    "    train_acc = H.history[\"acc\"]\n",
    "    val_acc = H.history[\"val_acc\"]\n",
    "\n",
    "    fitness = (sum(train_acc)/len(train_acc))\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testa cada indivíduo da População e obtém o fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data matrix: 4.32MB\n",
      "Epoch 1/3\n",
      "3/3 [==============================] - 2s 550ms/step - loss: nan - acc: 0.1455 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 0s 34ms/step - loss: nan - acc: 0.2667 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 0s 29ms/step - loss: nan - acc: 0.3636 - val_loss: nan - val_acc: 0.0000e+00\n",
      "[INFO] data matrix: 4.32MB\n",
      "Epoch 1/3\n",
      "3/3 [==============================] - 2s 588ms/step - loss: 7.4737 - acc: 0.2000 - val_loss: 4.4456 - val_acc: 0.5000\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.1949 - acc: 0.0727 - val_loss: 4.4593 - val_acc: 0.5000\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 6.0629 - acc: 0.3714 - val_loss: 4.4836 - val_acc: 0.5000\n",
      "[INFO] data matrix: 4.32MB\n",
      "Epoch 1/3\n",
      "3/3 [==============================] - 2s 648ms/step - loss: nan - acc: 0.3636 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 0s 38ms/step - loss: nan - acc: 0.1333 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 0s 28ms/step - loss: nan - acc: 0.5636 - val_loss: nan - val_acc: 0.0000e+00\n",
      "[INFO] data matrix: 4.32MB\n",
      "Epoch 1/3\n",
      "3/3 [==============================] - 2s 637ms/step - loss: 3.0941 - acc: 0.1333 - val_loss: 16.1181 - val_acc: 0.2500\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.7985 - acc: 0.0727 - val_loss: 16.1181 - val_acc: 0.2500\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.0985 - acc: 0.0727 - val_loss: 12.3040 - val_acc: 0.7500\n",
      "[INFO] data matrix: 4.32MB\n",
      "Epoch 1/3\n",
      "3/3 [==============================] - 2s 636ms/step - loss: 5.9029 - acc: 0.3333 - val_loss: 0.3034 - val_acc: 0.0000e+00\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 4.0087 - acc: 0.3636 - val_loss: 0.4719 - val_acc: 0.0000e+00\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.6746 - acc: 0.0727 - val_loss: 0.3033 - val_acc: 0.0000e+00\n",
      "[INFO] data matrix: 4.32MB\n",
      "Epoch 1/3\n",
      "3/3 [==============================] - 2s 688ms/step - loss: 9.7203 - acc: 0.2667 - val_loss: 1.1921e-07 - val_acc: 0.5000\n",
      "Epoch 2/3\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 7.3606 - acc: 0.3455 - val_loss: 0.0207 - val_acc: 0.2500\n",
      "Epoch 3/3\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.7831 - acc: 0.2182 - val_loss: 0.4618 - val_acc: 0.2500\n",
      "0.3010101077532527\n",
      "0.1922077943623324\n",
      "0.3474747522009743\n",
      "0.10505050661587956\n",
      "0.29292929955203123\n",
      "0.24040404579254113\n"
     ]
    }
   ],
   "source": [
    "def get_fitness(population):\n",
    "    #inicia a matrix 2x6 da população\n",
    "    population_matrix = [[0]*2 for i in range(6)]\n",
    "    \n",
    "    #Obtém fitness do indivíduo 1\n",
    "    population_matrix[0][0] = population[0]\n",
    "    population_matrix[0][1] = execute_rna(population[0][0], population[0][1], population[0][2], population[0][3], population[0][4], population[0][5], population[0][6], population[0][7])\n",
    "\n",
    "    \n",
    "    #Obtém fitness do indivíduo 2\n",
    "    population_matrix[1][0] = population[1]\n",
    "    population_matrix[1][1] = execute_rna(population[1][0], population[1][1], population[1][2], population[1][3], population[1][4], population[1][5], population[1][6], population[1][7])\n",
    "\n",
    "    #Obtém fitness do indivíduo 3\n",
    "    population_matrix[2][0] = population[2]\n",
    "    population_matrix[2][1] = execute_rna(population[2][0], population[2][1], population[2][2], population[2][3], population[2][4], population[2][5], population[2][6], population[2][7])\n",
    "\n",
    "    #Obtém fitness do indivíduo 4\n",
    "    population_matrix[3][0] = population[3]\n",
    "    population_matrix[3][1] = execute_rna(population[3][0], population[3][1], population[3][2], population[3][3], population[3][4], population[3][5], population[3][6], population[3][7])\n",
    "\n",
    "    #Obtém fitness do indivíduo 5\n",
    "    population_matrix[4][0] = population[4]\n",
    "    population_matrix[4][1] = execute_rna(population[4][0], population[4][1], population[4][2], population[4][3], population[4][4], population[4][5], population[4][6], population[4][7])\n",
    "\n",
    "    #Obtém fitness do indivíduo 6\n",
    "    population_matrix[5][0] = population[5]\n",
    "    population_matrix[5][1] = execute_rna(population[5][0], population[5][1], population[5][2], population[5][3], population[5][4], population[5][5], population[5][6], population[5][7])\n",
    "\n",
    "    return(population_matrix)\n",
    "\n",
    "population = init_new_population(6)\n",
    "population_fitness = get_fitness(population)\n",
    "print(population_fitness[0][1])\n",
    "print(population_fitness[1][1])\n",
    "print(population_fitness[2][1])\n",
    "print(population_fitness[3][1])\n",
    "print(population_fitness[4][1])\n",
    "print(population_fitness[5][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 12, 23, 234, 342, 1234]\n"
     ]
    }
   ],
   "source": [
    "def select_best_individuals(population):\n",
    "\n",
    "    list = [2,5,342,12,234,1234,23]\n",
    "    list.sort()\n",
    "    print(list)\n",
    "\n",
    "population = init_new_population(6)\n",
    "population_fitness = get_fitness(population)\n",
    "    \n",
    "select_best_individuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[1, 2, 3, 4] [11, 12, 13, 14]\n",
      "[1, 2, 3, 14] [11, 12, 13, 4]\n"
     ]
    }
   ],
   "source": [
    "def crossover_individuals():\n",
    "    \"\"\"\n",
    "    Slices both dna1 and dna2 into two parts at a random index within their\n",
    "    length and merges them. Both keep their initial sublist up to the crossover\n",
    "    index, but their ends are swapped.\n",
    "    \"\"\"\n",
    "    list1 = [1,2,3,4]\n",
    "    list2 = [11,12,13,14]\n",
    "    pos=int(random.random()*len(list1))\n",
    "    print(pos)\n",
    "    print(list1, list2)\n",
    "    print(list1[:pos]+list2[pos:], list2[:pos]+list1[pos:])\n",
    "    \n",
    "crossover_individuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_float():\n",
    "    \"\"\"\n",
    "    Return a random number between -1 and 1\n",
    "    \"\"\"\n",
    "    return random.uniform(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mutate():\n",
    "    \"\"\"\n",
    "    For each gene in the DNA, there is a 1/mutation_chance chance that it will be\n",
    "    switched out with a random character. This ensures diversity in the\n",
    "    population, and ensures that is difficult to get stuck in local minima.\n",
    "    \"\"\"\n",
    "    mutation_chance = 100\n",
    "    index = 0\n",
    "    dna_out=[]\n",
    "    list1 = [1,2,3,4,5,6,7,8,9,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "\n",
    "    for i in list1:\n",
    "        if int(random.random()*mutation_chance) == 1:\n",
    "            dna_out.insert(index, random_float())\n",
    "        else:\n",
    "            dna_out.insert(index, i)\n",
    "        index+1\n",
    "\n",
    "    print(list(reversed(dna_out)))\n",
    "\n",
    "mutate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
